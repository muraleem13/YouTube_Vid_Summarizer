{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33262205",
   "metadata": {
    "papermill": {
     "duration": 0.007387,
     "end_time": "2025-04-22T07:05:56.118973",
     "exception": false,
     "start_time": "2025-04-22T07:05:56.111586",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Enhancing Learning with AI: Building a YouTube Video Summarizer with Quiz and Flashcard Generation**\n",
    "# (Gen AI Intensive Course Capstone Project with Google and Kaggle 2025Q1)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# **Problem Statement**\n",
    "In today's fast-paced educational landscape,YouTube has become an invaluable educational resource, but lengthy videos can be time-consuming to process.Students and learners struggle to effectively extract, process, and retain key information from educational YouTube videos, which are often lengthy and time-consuming to watch in full. Most existing solutions focus solely on summarization without creating a complete learning ecosystem (summaries + quizzes + flashcards) from video content or specifically targeting educational contexts.There is a need for an automated tool that can transform these videos into concise, accessible learning materials that support different learning styles and improve knowledge retention.\n",
    "\n",
    "---\n",
    "\n",
    "# **Solution**\n",
    "\n",
    "Our **YouTube Video Summarizer Project** addresses this challenge by **leveraging generative AI capabilities** to transform educational videos into concise summaries, interactive quizzes, and flashcards - creating a comprehensive learning ecosystem from a single video link.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# **GenAI Capabilities Used**\n",
    "\n",
    "1. **Document understanding** - Our model processes and comprehends YouTube video transcripts, extracting meaning to generate summaries, quizzes, and flashcards.\n",
    "2. **Few-shot prompting** - Our code uses few-shot learning effectively in the quiz and flashcard generators by providing example format and structure for the AI to follow.\n",
    "3. **Structured output/JSON mode** - Generates structured JSON for quiz questions and flashcards, ensuring consistent formatting for downstream applications.\n",
    "4. **Long Context Window** - Our application leverages Gemini's long context window capabilities to maintain coherence throughout the entire transcript.\n",
    "---\n",
    "\n",
    "\n",
    "# 1. **Document Understanding**\n",
    "Document understanding in this context refers to the AI model's ability to process and extract meaningful information from YouTube video transcripts.\n",
    "# How It Works\n",
    "1. **Text Processing**- The model ingests the raw transcript text from a YouTube video\n",
    "2. **Comprehension**- It analyzes the content, identifying key concepts, themes, arguments, and important details.\n",
    "3. **Contextual Understanding**- It establishes relationships between different parts of the transcript.\n",
    "4. **Information Extraction**- It pulls out the most significant information based on the intended output.\n",
    "\n",
    "# Use Cases\n",
    "- Students looking to study educational content more efficiently.\n",
    "- Professionals needing quick insights from lengthy presentations.\n",
    "- Content creators wanting to provide supplementary materials.\n",
    "- Educators creating assessment materials based on video lectures\n",
    "- Anyone seeking to better retain information from video content.\n",
    "---\n",
    "# 2. **Few-Shot Prompting**\n",
    "**Few-shot prompting** is a technique where you provide a model with a small number of examples that demonstrate the task you want it to perform before asking it to complete a new instance of that task.\n",
    "Instead of explicitly explaining the rules or format, you simply show the model a few examples of input-output pairs, and then provide a new input, expecting the model to recognize the pattern and produce the appropriate output.\n",
    "For example, if you wanted me to translate English to French, a few-shot prompt might look like:\n",
    "- English: Hello\n",
    "- French: Bonjour\n",
    "- English: Thank you\n",
    "- French: Merci\n",
    "- English: How are you?\n",
    "- French: Comment allez-vous?\n",
    "- English: Good morning\n",
    "- French: [Here I would complete the pattern by answering \"Bonjour\" or \"Bon matin\"]\n",
    "  \n",
    "**Few-shot prompting** is particularly effective because:\n",
    "\n",
    "- It demonstrates the task through examples rather than explanations.\n",
    "- It provides context for how to approach the problem.\n",
    "- It works well for tasks that are difficult to explicitly define but easy to demonstrate.\n",
    "- It helps models understand tone, format, and style expectations.\n",
    "\n",
    "This technique is a powerful way to guide AI models like me to produce more accurate and useful responses without having to explicitly code or fine-tune the model for each specific task.\n",
    "\n",
    "---\n",
    "\n",
    "# 3. **Structured Output/JSON mode**\n",
    "Structured output refers to formatting AI responses in a specific, machine-readable structure rather than natural language prose. JSON mode is a popular implementation of this approach.\n",
    "# JSON\n",
    "JSON mode is a special prompt format that instructs an AI model to respond exclusively in valid JSON format. This is particularly useful when:\n",
    "\n",
    "- You need to parse the AI's response programmatically.\n",
    "- You're building applications that need consistent data structures.\n",
    "- You're creating API integrations that require standardized formats.\n",
    "\n",
    "# How It Works\n",
    "1. Specify in your prompt that you want JSON output.\n",
    "2. Define the structure you expect (often with an example).\n",
    "3. The AI then generates a response following that structure.\n",
    "\n",
    "# Example\n",
    "Instead of asking:\n",
    "- ``` Tell me about the three largest planets in our solar system```\n",
    "You might use JSON mode by saying:\n",
    "- ```Return information about the three largest planets in our solar system in JSON format with fields for name, diameter, and interesting fact.```\n",
    "The response would then be:\n",
    "```\n",
    "{\n",
    "  \"planets\": [\n",
    "    {\n",
    "      \"name\": \"Jupiter\",\n",
    "      \"diameter\": 139820,\n",
    "      \"diameterUnit\": \"km\",\n",
    "      \"interestingFact\": \"Jupiter has the Great Red Spot, a storm that has been raging for at least 400 years\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Saturn\",\n",
    "      \"diameter\": 116460,\n",
    "      \"diameterUnit\": \"km\",\n",
    "      \"interestingFact\": \"Saturn's rings are made mostly of ice particles with some rocky debris\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Uranus\",\n",
    "      \"diameter\": 50724,\n",
    "      \"diameterUnit\": \"km\",\n",
    "      \"interestingFact\": \"Uranus rotates on its side with an axial tilt of about 98 degrees\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# **Long Context Window**\n",
    "Long context windows in language models refer to the maximum amount of text or tokens that the model can process and \"remember\" at once during a task. This capability determines how much previous information the model can reference when generating responses.\n",
    "\n",
    "Traditional language models have been limited to processing sequences of a few thousand tokens. Long context window models expand this capacity significantly—some can handle tens of thousands or even millions of tokens in a single session.\n",
    "This expanded capacity allows these models to:\n",
    "\n",
    "1. Process entire documents, books, or transcripts in a single pass\n",
    "2. Maintain coherence across lengthy analyses\n",
    "3. Reference information from much earlier in the conversation or document\n",
    "4. Understand complex relationships between distant parts of a text\n",
    "5. Perform tasks requiring integration of information across large volumes of content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74becfea",
   "metadata": {
    "papermill": {
     "duration": 0.005924,
     "end_time": "2025-04-22T07:05:56.131419",
     "exception": false,
     "start_time": "2025-04-22T07:05:56.125495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Core Processing Pipeline**\n",
    "\n",
    "1. API Configuration\n",
    "    * Get Gemini API key from Kaggle secrets\n",
    "    * Configure Gemini API with the retrieved key\n",
    "2. Input Processing\n",
    "    * Accept YouTube URL from user\n",
    "    * Extract video ID using regex pattern matching\n",
    "    * Determine user preferences for quiz and flashcard generation\n",
    "3. Transcript Extraction\n",
    "    * Use YouTubeTranscriptApi to get video transcript\n",
    "    * Join transcript segments into complete text\n",
    "4. Summary Generation\n",
    "    * Use Gemini AI model (gemini-2.0-flash)\n",
    "    * Generate markdown-formatted summary with specific structure:\n",
    "        * Level 1 heading for title\n",
    "        * Brief introduction\n",
    "        * Key points under level 2 headings\n",
    "        * Markdown formatting (bullets, bold, blockquotes)\n",
    "    * Save summary to file (summaries/summary_{video_id}.md)\n",
    "5. Quiz Generation (Optional)\n",
    "    *  Generate quiz questions based on transcript content\n",
    "    *  Format as multiple choice with explanations\n",
    "    *  Save quiz to file (quizzes/quiz_{video_id}.json)\n",
    "    *  Provide interactive quiz interface\n",
    "6. Flashcard Generation (Optional)\n",
    "    * Generate flashcards at specified complexity level (undergraduate/graduate/mixed)\n",
    "    * Format as JSON with front (term), back (definition), and category\n",
    "    * Save flashcards to file (flashcards/flashcards_{video_id}.json)\n",
    "    * Provide interactive flashcard review interface \n",
    "7. Output Display\n",
    "    * Display markdown summary\n",
    "    * Run interactive quiz if generated\n",
    "    * Display interactive flashcards if generated \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e765b24",
   "metadata": {
    "papermill": {
     "duration": 0.005901,
     "end_time": "2025-04-22T07:05:56.143461",
     "exception": false,
     "start_time": "2025-04-22T07:05:56.137560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Note:**\n",
    "**Before running this notebook, make sure to:**\n",
    "- Install all required dependencies via **Add-ons → Install Dependencies**.\n",
    "- Set the API key using **Add-ons → Set API Key**.\n",
    "- **This notebook is designed for interactive learning. Due to Kaggle's limitations, dynamic input does not work on frontend. On local environments, this supports full interactivity.**\n",
    "\n",
    "- Please refer to the youtube link for live demostration\n",
    "https://www.youtube.com/watch?v=6jQkXHED-b4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fbf81a",
   "metadata": {
    "papermill": {
     "duration": 0.005801,
     "end_time": "2025-04-22T07:05:56.155301",
     "exception": false,
     "start_time": "2025-04-22T07:05:56.149500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Function to get API key from Kaggle secrets\n",
    "- Get the Gemini API key from Kaggle secrets.\n",
    "- Returns the API key as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b781bd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:05:56.169267Z",
     "iopub.status.busy": "2025-04-22T07:05:56.168646Z",
     "iopub.status.idle": "2025-04-22T07:05:56.178240Z",
     "shell.execute_reply": "2025-04-22T07:05:56.177228Z"
    },
    "papermill": {
     "duration": 0.018713,
     "end_time": "2025-04-22T07:05:56.180106",
     "exception": false,
     "start_time": "2025-04-22T07:05:56.161393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_genai_api_key():\n",
    "    try:\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "        user_secrets = UserSecretsClient()\n",
    "        genai_api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "        return genai_api_key\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching API key: {e}\")\n",
    "        print(\"Please make sure you've added the GOOGLE_API_KEY to your Kaggle secrets.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36505b44",
   "metadata": {
    "papermill": {
     "duration": 0.006082,
     "end_time": "2025-04-22T07:05:56.192295",
     "exception": false,
     "start_time": "2025-04-22T07:05:56.186213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Function which Configures Gemini API with key\n",
    "- Configure the Gemini API with the API key.\n",
    "- Returns True if successful, False otherwise.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c80ea42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:05:56.207078Z",
     "iopub.status.busy": "2025-04-22T07:05:56.206755Z",
     "iopub.status.idle": "2025-04-22T07:05:56.211850Z",
     "shell.execute_reply": "2025-04-22T07:05:56.210753Z"
    },
    "papermill": {
     "duration": 0.013941,
     "end_time": "2025-04-22T07:05:56.213397",
     "exception": false,
     "start_time": "2025-04-22T07:05:56.199456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def configure_genai():\n",
    "    api_key = get_genai_api_key()\n",
    "    if api_key:\n",
    "        genai.configure(api_key=api_key)\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d4757",
   "metadata": {
    "papermill": {
     "duration": 0.005662,
     "end_time": "2025-04-22T07:05:56.225147",
     "exception": false,
     "start_time": "2025-04-22T07:05:56.219485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf00dc7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:05:56.238383Z",
     "iopub.status.busy": "2025-04-22T07:05:56.237982Z",
     "iopub.status.idle": "2025-04-22T07:06:06.088728Z",
     "shell.execute_reply": "2025-04-22T07:06:06.087316Z"
    },
    "papermill": {
     "duration": 9.859533,
     "end_time": "2025-04-22T07:06:06.090691",
     "exception": false,
     "start_time": "2025-04-22T07:05:56.231158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube_transcript_api\r\n",
      "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\r\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (0.7.1)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (2.32.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2025.1.31)\r\n",
      "Downloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: youtube_transcript_api\r\n",
      "Successfully installed youtube_transcript_api-1.0.3\r\n",
      "Collecting dotenv\r\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\r\n",
      "Collecting python-dotenv (from dotenv)\r\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\r\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\r\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\r\n",
      "Installing collected packages: python-dotenv, dotenv\r\n",
      "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "! pip install youtube_transcript_api\n",
    "! pip install dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dcab6d",
   "metadata": {
    "papermill": {
     "duration": 0.006367,
     "end_time": "2025-04-22T07:06:06.104062",
     "exception": false,
     "start_time": "2025-04-22T07:06:06.097695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import all the required modules for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1146cc9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:06:06.120127Z",
     "iopub.status.busy": "2025-04-22T07:06:06.119769Z",
     "iopub.status.idle": "2025-04-22T07:06:08.833671Z",
     "shell.execute_reply": "2025-04-22T07:06:08.832497Z"
    },
    "papermill": {
     "duration": 2.724861,
     "end_time": "2025-04-22T07:06:08.835556",
     "exception": false,
     "start_time": "2025-04-22T07:06:06.110695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import io\n",
    "import random\n",
    "import google.generativeai as genai\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from dotenv import load_dotenv\n",
    "from warnings import filterwarnings\n",
    "from IPython.display import HTML, Markdown, display\n",
    "from warnings import filterwarnings\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22d95b1",
   "metadata": {
    "papermill": {
     "duration": 0.007087,
     "end_time": "2025-04-22T07:06:08.850702",
     "exception": false,
     "start_time": "2025-04-22T07:06:08.843615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Function for Video ID Extraction using 're' module for pattern matching\n",
    "- Extract the video ID from different YouTube URL formats.\n",
    "- Handles full YouTube.com URLs and YouTube shortened URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b8eba32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:06:08.866429Z",
     "iopub.status.busy": "2025-04-22T07:06:08.865928Z",
     "iopub.status.idle": "2025-04-22T07:06:08.871562Z",
     "shell.execute_reply": "2025-04-22T07:06:08.870462Z"
    },
    "papermill": {
     "duration": 0.015545,
     "end_time": "2025-04-22T07:06:08.873300",
     "exception": false,
     "start_time": "2025-04-22T07:06:08.857755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_video_id(url):\n",
    "    youtube_pattern = r'(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
    "    \n",
    "    match = re.search(youtube_pattern, url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        raise ValueError(\"Could not extract video ID from URL. Please check the URL format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fc4657",
   "metadata": {
    "papermill": {
     "duration": 0.006922,
     "end_time": "2025-04-22T07:06:08.886969",
     "exception": false,
     "start_time": "2025-04-22T07:06:08.880047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Function for Youtube Video Transcript Extraction\n",
    "- Extract transcript for a YouTube video in English by default.\n",
    "- Returns the full transcript text as a string by extracting and joining transcript text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c12d498c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:06:08.903953Z",
     "iopub.status.busy": "2025-04-22T07:06:08.903623Z",
     "iopub.status.idle": "2025-04-22T07:06:08.909446Z",
     "shell.execute_reply": "2025-04-22T07:06:08.908451Z"
    },
    "papermill": {
     "duration": 0.017711,
     "end_time": "2025-04-22T07:06:08.911257",
     "exception": false,
     "start_time": "2025-04-22T07:06:08.893546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_transcript(video_id, language='en'):\n",
    "    try:\n",
    "        transcript_content = YouTubeTranscriptApi.get_transcript(video_id=video_id, languages=[language])\n",
    "        \n",
    "        transcript = ' '.join([i['text'] for i in transcript_content])\n",
    "        \n",
    "        return transcript\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting transcript: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4fd630",
   "metadata": {
    "papermill": {
     "duration": 0.006425,
     "end_time": "2025-04-22T07:06:08.924569",
     "exception": false,
     "start_time": "2025-04-22T07:06:08.918144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Function for Generating Summary from Video\n",
    "- Generate a summary of the transcript using Google's Gemini AI in Markdown format.\n",
    "- Returns the markdown-formatted summary text.\n",
    "- Define a prompt for AI model that specifically requests Markdown\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b68b06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:06:08.939353Z",
     "iopub.status.busy": "2025-04-22T07:06:08.939021Z",
     "iopub.status.idle": "2025-04-22T07:06:08.945797Z",
     "shell.execute_reply": "2025-04-22T07:06:08.944824Z"
    },
    "papermill": {
     "duration": 0.016522,
     "end_time": "2025-04-22T07:06:08.947650",
     "exception": false,
     "start_time": "2025-04-22T07:06:08.931128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_markdown_summary(transcript_text, video_id=None):\n",
    "    try:\n",
    "        if not configure_genai():\n",
    "            return \"API configuration failed. Unable to generate summary.\"\n",
    "        \n",
    "        model = genai.GenerativeModel(model_name='gemini-2.0-flash')\n",
    "        \n",
    "        video_info = f\"Video: {video_id}\\n\\n\" if video_id else \"\"\n",
    "        \n",
    "        prompt = f\"\"\"You are a YouTube video summarizer that creates well-formatted Markdown summaries.\n",
    "\n",
    "Based on the transcript I'm providing, create a comprehensive summary (within 500 words) with the following:\n",
    "\n",
    "1. Start with a level 1 heading (# ) for the main title that captures the essence of the content\n",
    "2. Include a brief introduction paragraph\n",
    "3. Organize key points under level 2 headings (## )\n",
    "4. Use appropriate Markdown formatting:\n",
    "   - Bullet points for lists\n",
    "   - Bold text for emphasis\n",
    "   - Blockquotes for notable quotes\n",
    "   - Code blocks for technical content if relevant\n",
    "   - Tables if comparing information is valuable\n",
    "\n",
    "Here's the transcript to summarize:\n",
    "\n",
    "{transcript_text}\"\"\"\n",
    "        \n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        markdown_summary = video_info + response.text\n",
    "        \n",
    "        return markdown_summary\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating summary: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b53b56",
   "metadata": {
    "papermill": {
     "duration": 0.006251,
     "end_time": "2025-04-22T07:06:08.960684",
     "exception": false,
     "start_time": "2025-04-22T07:06:08.954433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Function for Generating Quiz\n",
    "- The function **generate_quiz** creates multiple-choice questions based on a given text summary\n",
    "- It has parameters for the **number of questions (default is 10)** and **difficulty level (\"mixed\" by default)**\n",
    "- It uses Google's Generative AI **(Gemini 2.0 Flash model)** to generate the questions\n",
    "- The difficulty can be set to **\"undergraduate,\" \"graduate,\" or \"mixed\" (default)**\n",
    "- For each difficulty level, it provides specific instructions for question generation:\n",
    "    - **Undergraduate**: focuses on fundamentals and application\n",
    "    - **Graduate**: focuses on advanced analysis and synthesis for PhD students\n",
    "    - **Mixed**: creates a blend (60% undergraduate, 40% graduate level)\n",
    "\n",
    "- The function sends a detailed prompt to the AI model that includes:\n",
    "    - Instructions for question creation\n",
    "    - Examples of both undergraduate and graduate-level questions\n",
    "    - The summary text provided by the user\n",
    "- It formats the response as a **JSON** array containing multiple-choice questions\n",
    "  \n",
    "- Each question in the **JSON** includes:\n",
    "    - The question text\n",
    "    - Multiple answer options\n",
    "    - The correct answer (as a letter)\n",
    "    - An explanation for the correct answer\n",
    "\n",
    "\n",
    "- The code includes error handling for issues with:\n",
    "    - AI configuration  \n",
    "    - **JSON** parsing\n",
    "    - Other exceptions that might occur during execution\n",
    "\n",
    "- The function returns the **parsed quiz data if successful**, or **None if there's an error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8cd85ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:06:08.976213Z",
     "iopub.status.busy": "2025-04-22T07:06:08.975452Z",
     "iopub.status.idle": "2025-04-22T07:06:08.989388Z",
     "shell.execute_reply": "2025-04-22T07:06:08.988225Z"
    },
    "papermill": {
     "duration": 0.023571,
     "end_time": "2025-04-22T07:06:08.990997",
     "exception": false,
     "start_time": "2025-04-22T07:06:08.967426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_quiz(summary_text, num_questions=10, difficulty=\"mixed\"):\n",
    "    try:\n",
    "        if not configure_genai():\n",
    "            return None\n",
    "    \n",
    "        model = genai.GenerativeModel(model_name='gemini-2.0-flash')\n",
    "        \n",
    "        difficulty_instruction = \"\"\n",
    "        if difficulty == \"undergraduate\":\n",
    "            difficulty_instruction = \"Create questions suitable for undergraduate students, focusing on fundamental understanding and application of concepts.\"\n",
    "        elif difficulty == \"graduate\":\n",
    "            difficulty_instruction = \"Create questions suitable for PhD students, focusing on advanced analysis, synthesis of complex ideas, and evaluation of theoretical implications.\"\n",
    "        else:  \n",
    "            difficulty_instruction = \"Create a mix of questions with varying difficulty levels: 60% at undergraduate level (fundamental understanding and application) and 40% at graduate/PhD level (advanced analysis and synthesis of complex concepts).\"\n",
    "        \n",
    "        prompt = f\"\"\"Based on a given summary, create {num_questions} multiple-choice questions to test understanding of the content.\n",
    "\n",
    "{difficulty_instruction}\n",
    "\n",
    "Here are examples at two different academic levels:\n",
    "\n",
    "UNDERGRADUATE LEVEL EXAMPLE (Medium Difficulty):\n",
    "Summary: Climate change refers to long-term shifts in temperatures and weather patterns. These shifts may be natural, but since the 1800s, human activities have been the main driver of climate change, primarily due to the burning of fossil fuels like coal, oil, and gas, which produces heat-trapping gases. The primary greenhouse gases include carbon dioxide, methane, nitrous oxide, and fluorinated gases. Global warming is causing polar ice sheets and glaciers to melt, raising sea levels and threatening coastal communities. Climate models project that without significant mitigation efforts, global temperatures could rise by 2.7°F to 8.6°F by 2100, with catastrophic consequences including extreme weather events, biodiversity loss, food insecurity, and economic damage. The Paris Agreement, adopted in 2015, aims to limit global warming to well below 2°C, preferably 1.5°C, compared to pre-industrial levels through nationally determined contributions to greenhouse gas reductions.\n",
    "\n",
    "Questions:\n",
    "[\n",
    "  {{\n",
    "    \"question\": \"Which human activity has been identified as the main driver of climate change since the 1800s?\",\n",
    "    \"options\": [\n",
    "      \"Deforestation\",\n",
    "      \"Agriculture\",\n",
    "      \"Burning fossil fuels\",\n",
    "      \"Urbanization\"\n",
    "    ],\n",
    "    \"answer\": \"C\",\n",
    "    \"explanation\": \"While all options contribute to climate change, the burning of fossil fuels (coal, oil, and gas) has been the primary human activity driving climate change since the Industrial Revolution, as it releases significant amounts of carbon dioxide into the atmosphere.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"question\": \"What is the main goal of the 2015 Paris Agreement?\",\n",
    "    \"options\": [\n",
    "      \"To eliminate the use of all fossil fuels by 2050\",\n",
    "      \"To limit global warming to well below 2°C compared to pre-industrial levels\",\n",
    "      \"To provide funding for developing countries affected by climate change\",\n",
    "      \"To establish a global carbon tax\"\n",
    "    ],\n",
    "    \"answer\": \"B\",\n",
    "    \"explanation\": \"The Paris Agreement's central aim is to strengthen the global response to climate change by keeping global temperature rise this century well below 2°C above pre-industrial levels and to pursue efforts to limit the temperature increase even further to 1.5°C.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"question\": \"Which of the following is a direct consequence of global warming on Earth's cryosphere?\",\n",
    "    \"options\": [\n",
    "      \"Increase in tropical storms\",\n",
    "      \"Ocean acidification\",\n",
    "      \"Melting of polar ice sheets\",\n",
    "      \"Rise in infectious diseases\"\n",
    "    ],\n",
    "    \"answer\": \"C\",\n",
    "    \"explanation\": \"Global warming directly causes the melting of the cryosphere (frozen parts of the Earth), including polar ice sheets and glaciers, which contributes to sea level rise.\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "GRADUATE/PhD LEVEL EXAMPLE (Advanced Difficulty):\n",
    "Summary: Epigenetics studies heritable changes in gene expression that don't involve alterations to the underlying DNA sequence. Key epigenetic mechanisms include DNA methylation, histone modifications, and non-coding RNAs. DNA methylation typically involves the addition of a methyl group to the 5' position of cytosine in CpG dinucleotides, often resulting in gene silencing. Histone modifications include acetylation, methylation, phosphorylation, and ubiquitination of histone tails, creating the \"histone code\" that influences chromatin structure and gene accessibility. The field has revealed remarkable plasticity in gene expression, with environmental factors like diet, stress, and toxin exposure capable of inducing epigenetic changes that may persist across generations through mechanisms like incomplete erasure during gametogenesis. This challenges traditional Mendelian inheritance models and has profound implications for understanding disease etiology, particularly in cancer, neurodevelopmental disorders, and metabolic diseases. Epigenetic dysregulation is now recognized as a hallmark of cancer, with global hypomethylation and gene-specific hypermethylation common across tumor types. Emerging epigenetic therapeutics include DNMT inhibitors, HDAC inhibitors, and approaches targeting reader proteins of epigenetic marks. The field's evolution has benefited from technological advances including bisulfite sequencing, ChIP-seq, and ATAC-seq, enabling genome-wide epigenetic profiling at unprecedented resolution.\n",
    "\n",
    "Questions:\n",
    "[\n",
    "  {{\n",
    "    \"question\": \"How does the transgenerational inheritance of environmentally-induced epigenetic modifications challenge classical genetic theory?\",\n",
    "    \"options\": [\n",
    "      \"It suggests that genetic mutations can be spontaneously reversed\",\n",
    "      \"It contradicts the central dogma of molecular biology\",\n",
    "      \"It challenges the Mendelian concept that inheritance occurs exclusively through DNA sequence transmission\",\n",
    "      \"It implies that mitochondrial DNA is more important than nuclear DNA\"\n",
    "    ],\n",
    "    \"answer\": \"C\",\n",
    "    \"explanation\": \"The inheritance of environmentally-induced epigenetic changes across generations challenges Mendelian genetics, which posits that inheritance occurs exclusively through transmission of DNA sequences. Epigenetic inheritance suggests that acquired characteristics can be passed to offspring without changes to DNA sequence, a concept that was previously rejected in classical genetics.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"question\": \"Which theoretical model best explains the observation that identical twins often show increasing epigenetic divergence as they age?\",\n",
    "    \"options\": [\n",
    "      \"Stochastic epigenetic drift in response to subtle environmental differences\",\n",
    "      \"Programmed epigenetic diversification driven by evolutionary advantage\",\n",
    "      \"Lamarckian inheritance of acquired characteristics\",\n",
    "      \"Random deamination of methylated cytosines\"\n",
    "    ],\n",
    "    \"answer\": \"A\",\n",
    "    \"explanation\": \"The increasing epigenetic divergence between identical twins over time is best explained by stochastic epigenetic drift in response to different environmental exposures. This model accounts for how genetically identical individuals develop different epigenetic profiles and potentially different phenotypes despite sharing identical DNA sequences.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"question\": \"In the context of cancer epigenetics, what mechanistic explanation best accounts for the paradoxical observation of global hypomethylation concurrent with gene-specific hypermethylation?\",\n",
    "    \"options\": [\n",
    "      \"Mutations in DNA methyltransferases that randomly alter their targeting\",\n",
    "      \"Differential activity of TET enzymes across genomic regions\",\n",
    "      \"Redistribution of DNMTs from repetitive elements to tumor suppressor promoters due to altered chromatin organization\",\n",
    "      \"Selective pressure that independently favors both hypomethylation and hypermethylation events\"\n",
    "    ],\n",
    "    \"answer\": \"C\",\n",
    "    \"explanation\": \"The paradox is best explained by the redistribution of DNA methyltransferases (DNMTs) from repetitive elements to specific gene promoters, particularly tumor suppressors. This is associated with altered nuclear architecture and chromatin reorganization in cancer cells, leading to simultaneous global hypomethylation (activating oncogenes and transposable elements) and targeted hypermethylation of tumor suppressor genes.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"question\": \"Which conceptual framework most accurately captures the relationship between genetic variants and epigenetic modifications in complex disease etiology?\",\n",
    "    \"options\": [\n",
    "      \"Genetic variants determine epigenetic patterns which then cause disease\",\n",
    "      \"Epigenetic modifications occur independently of genetic background\",\n",
    "      \"A bidirectional relationship where genetic variants can affect epigenetic modifications, while environmental factors can induce epigenetic changes that modulate genetic effects\",\n",
    "      \"Epigenetic modifications cause genetic mutations that lead to disease\"\n",
    "    ],\n",
    "    \"answer\": \"C\",\n",
    "    \"explanation\": \"Complex disease etiology is best understood through a bidirectional framework where genetic variants can influence epigenetic patterns (for example, mutations in epigenetic enzymes), while environmentally-induced epigenetic modifications can alter how genetic variants are expressed. This gene-environment interaction model explains why genetic risk factors show variable penetrance and why environmental exposures affect individuals differently based on their genetic background.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"question\": \"Which methodological approach would be most appropriate for investigating whether prenatal nutrition influences metabolic phenotypes through epigenetic reprogramming?\",\n",
    "    \"options\": [\n",
    "      \"A cross-sectional study comparing DNA methylation patterns in adults with different BMIs\",\n",
    "      \"A genome-wide association study correlating SNPs with metabolic traits\",\n",
    "      \"A longitudinal cohort study with maternal nutritional assessments, offspring cord blood epigenetic profiling, and follow-up metabolic phenotyping\",\n",
    "      \"An in vitro study of adipocyte differentiation under different nutrient conditions\"\n",
    "    ],\n",
    "    \"answer\": \"C\",\n",
    "    \"explanation\": \"A longitudinal cohort approach with maternal nutritional assessments, epigenetic profiling at birth (cord blood), and long-term follow-up is methodologically superior for establishing causal relationships between prenatal nutrition, epigenetic changes, and metabolic outcomes. This design accounts for temporal relationships and allows researchers to control for confounding variables while establishing the persistence of epigenetic changes and their association with metabolic phenotypes.\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "Now, based on the following summary, create {num_questions} multiple-choice questions:\n",
    "\n",
    "HERE IS THE SUMMARY:\n",
    "{summary_text}\n",
    "\n",
    "Respond ONLY with the properly formatted JSON array of questions. Do not include any introductory or explanatory text.\n",
    "\"\"\"\n",
    "        \n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        try:\n",
    "            json_text = response.text\n",
    "            if \"```json\" in json_text:\n",
    "                json_text = json_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "            elif \"```\" in json_text:\n",
    "                json_text = json_text.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "                \n",
    "            quiz_data = json.loads(json_text)\n",
    "            return quiz_data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from quiz generation: {e}\")\n",
    "            print(\"Response received:\", response.text[:100] + \"...\")\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating quiz: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e627a",
   "metadata": {
    "papermill": {
     "duration": 0.00669,
     "end_time": "2025-04-22T07:06:09.004716",
     "exception": false,
     "start_time": "2025-04-22T07:06:08.998026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Function for Running the Quiz\n",
    "- Takes **quiz_data** as input and shuffles questions to create a randomized quiz experience\n",
    "- Limits the quiz to a **maximum of 10 questions** and displays them with **multiple-choice options (A-D)**\n",
    "- Collects and **validates user answers**, providing immediate feedback after each question\n",
    "- **Keeps track of score** and displays the final result as both raw score and percentage\n",
    "- **Returns a structured dictionary** containing score, total questions, and detailed results for each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "072c251b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:06:09.019244Z",
     "iopub.status.busy": "2025-04-22T07:06:09.018903Z",
     "iopub.status.idle": "2025-04-22T07:06:09.027774Z",
     "shell.execute_reply": "2025-04-22T07:06:09.026834Z"
    },
    "papermill": {
     "duration": 0.018377,
     "end_time": "2025-04-22T07:06:09.029638",
     "exception": false,
     "start_time": "2025-04-22T07:06:09.011261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_quiz(quiz_data):\n",
    "    if not quiz_data:\n",
    "        print(\"No quiz data available.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"\\n===== QUIZ TIME =====\")\n",
    "    print(\"Answer the following questions based on the video content.\\n\")\n",
    "    \n",
    "    score = 0\n",
    "    results = []\n",
    "    \n",
    "    # Shuffle the questions for variety\n",
    "    random.shuffle(quiz_data)\n",
    "    \n",
    "    # Limit to the requested number of questions\n",
    "    quiz_data = quiz_data[:10]  # Default limit of 10 questions\n",
    "    \n",
    "    for i, q in enumerate(quiz_data, 1):\n",
    "        print(f\"\\nQuestion {i}: {q['question']}\")\n",
    "        \n",
    "        # Print options\n",
    "        for j, option in enumerate(['A', 'B', 'C', 'D']):\n",
    "            if j < len(q['options']):  # Ensure we have enough options\n",
    "                print(f\"{option}. {q['options'][j]}\")\n",
    "        \n",
    "        # Get user answer\n",
    "        user_answer = input(\"\\nYour answer (A/B/C/D): \").strip().upper()\n",
    "        \n",
    "        # Check if answer is correct\n",
    "        correct_answer = q['answer'].upper()\n",
    "        is_correct = user_answer == correct_answer\n",
    "        \n",
    "        if is_correct:\n",
    "            print(\"✓ Correct!\")\n",
    "            score += 1\n",
    "        else:\n",
    "            print(f\"✗ Incorrect. The correct answer is {correct_answer}.\")\n",
    "        \n",
    "        # Show explanation\n",
    "        if 'explanation' in q:\n",
    "            print(f\"Explanation: {q['explanation']}\")\n",
    "        \n",
    "        # Save result\n",
    "        results.append({\n",
    "            'question': q['question'],\n",
    "            'user_answer': user_answer,\n",
    "            'correct_answer': correct_answer,\n",
    "            'is_correct': is_correct\n",
    "        })\n",
    "    \n",
    "    # Show final score\n",
    "    print(f\"\\n===== Quiz Complete =====\")\n",
    "    print(f\"Your score: {score}/{len(quiz_data)} ({score/len(quiz_data)*100:.1f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'score': score,\n",
    "        'total': len(quiz_data),\n",
    "        'results': results\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b1a8c",
   "metadata": {
    "papermill": {
     "duration": 0.006398,
     "end_time": "2025-04-22T07:06:09.042973",
     "exception": false,
     "start_time": "2025-04-22T07:06:09.036575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Function for Generating FalshCards Using 'Few-Shot Prompting and Structured Output/JSON mode' Technique \n",
    "- **Parameter**:\n",
    "    - **Summary_text**:the text summary to base the flashcards\n",
    "    - **max_cards**:Maximum number of flashcards to generate\n",
    "    - **complexity**:\"undergraduate\", \"graduate\", or \"mixed\" (default)\n",
    "\n",
    "- **Define a prompt** with examples at different academic levels\n",
    "\n",
    "- Processes the AI response by extracting JSON data from code blocks (handles both ````**json**` and general ````` delimiters)\n",
    "\n",
    "- Implements **JSON** parsing with **json.loads()** for converting the text response into structured flashcard data\n",
    "\n",
    "- Contains comprehensive error handling with multiple try/except blocks to manage configuration failures, **JSON decoding errors**, and general exceptions\n",
    "\n",
    "- **Returns a list of flashcards dictionaries** with front, back, and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2e58aa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:06:09.058138Z",
     "iopub.status.busy": "2025-04-22T07:06:09.057809Z",
     "iopub.status.idle": "2025-04-22T07:06:09.069290Z",
     "shell.execute_reply": "2025-04-22T07:06:09.068334Z"
    },
    "papermill": {
     "duration": 0.021539,
     "end_time": "2025-04-22T07:06:09.070968",
     "exception": false,
     "start_time": "2025-04-22T07:06:09.049429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_flashcards(summary_text, max_cards=10, complexity=\"mixed\"):\n",
    "    try:\n",
    "        if not configure_genai():\n",
    "            return None\n",
    "        \n",
    "        model = genai.GenerativeModel(model_name='gemini-2.0-flash')\n",
    "        \n",
    "        complexity_instruction = \"\"\n",
    "        if complexity == \"undergraduate\":\n",
    "            complexity_instruction = \"Create flashcards appropriate for undergraduate students, focusing on foundational terms and straightforward definitions that demonstrate core concepts in the field.\"\n",
    "        elif complexity == \"graduate\":\n",
    "            complexity_instruction = \"Create flashcards appropriate for graduate students, focusing on advanced terminology, specialized concepts, nuanced definitions, and theoretical frameworks that would be relevant to advanced study or research.\"\n",
    "        else: \n",
    "            complexity_instruction = \"Create a mix of flashcards with varying academic levels: 60% at undergraduate level (core concepts) and 40% at graduate level (specialized terminology and advanced theoretical concepts).\"\n",
    "        \n",
    "        prompt = f\"\"\"Based on the following summary, create flashcards ONLY for definitions/terms found in the content.\n",
    "Do NOT create flashcards if no clear definitions exist in the text.\n",
    "Create up to {max_cards} flashcards, but ONLY include actual definitions from the text.\n",
    "\n",
    "{complexity_instruction}\n",
    "\n",
    "Here are examples of flashcards at different academic levels:\n",
    "\n",
    "UNDERGRADUATE LEVEL EXAMPLE:\n",
    "Summary: Climate change refers to long-term shifts in temperatures and weather patterns. These shifts may be natural, but since the 1800s, human activities have been the main driver of climate change, primarily due to the burning of fossil fuels like coal, oil, and gas, which produces heat-trapping gases. The primary greenhouse gases include carbon dioxide, methane, nitrous oxide, and fluorinated gases. Global warming is causing polar ice sheets and glaciers to melt, raising sea levels and threatening coastal communities. Climate models project that without significant mitigation efforts, global temperatures could rise by 2.7°F to 8.6°F by 2100, with catastrophic consequences including extreme weather events, biodiversity loss, food insecurity, and economic damage. The Paris Agreement, adopted in 2015, aims to limit global warming to well below 2°C, preferably 1.5°C, compared to pre-industrial levels through nationally determined contributions to greenhouse gas reductions.\n",
    "\n",
    "Flashcards:\n",
    "[\n",
    "  {{\n",
    "    \"front\": \"Climate change\",\n",
    "    \"back\": \"Long-term shifts in temperatures and weather patterns, primarily driven by human activities since the 1800s, especially the burning of fossil fuels.\",\n",
    "    \"category\": \"Environmental Science\"\n",
    "  }},\n",
    "  {{\n",
    "    \"front\": \"Greenhouse gases\",\n",
    "    \"back\": \"Heat-trapping gases that contribute to climate change, including carbon dioxide, methane, nitrous oxide, and fluorinated gases.\",\n",
    "    \"category\": \"Atmospheric Chemistry\"\n",
    "  }},\n",
    "  {{\n",
    "    \"front\": \"Global warming\",\n",
    "    \"back\": \"The increase in Earth's average temperature that causes polar ice sheets and glaciers to melt, raising sea levels and threatening coastal communities.\",\n",
    "    \"category\": \"Climate Effects\"\n",
    "  }},\n",
    "  {{\n",
    "    \"front\": \"Paris Agreement\",\n",
    "    \"back\": \"An international climate accord adopted in 2015 that aims to limit global warming to well below 2°C, preferably 1.5°C, compared to pre-industrial levels through nationally determined contributions.\",\n",
    "    \"category\": \"Climate Policy\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "GRADUATE LEVEL EXAMPLE:\n",
    "Summary: Epigenetics studies heritable changes in gene expression that don't involve alterations to the underlying DNA sequence. Key epigenetic mechanisms include DNA methylation, histone modifications, and non-coding RNAs. DNA methylation typically involves the addition of a methyl group to the 5' position of cytosine in CpG dinucleotides, often resulting in gene silencing. Histone modifications include acetylation, methylation, phosphorylation, and ubiquitination of histone tails, creating the \"histone code\" that influences chromatin structure and gene accessibility. The field has revealed remarkable plasticity in gene expression, with environmental factors like diet, stress, and toxin exposure capable of inducing epigenetic changes that may persist across generations through mechanisms like incomplete erasure during gametogenesis. This challenges traditional Mendelian inheritance models and has profound implications for understanding disease etiology, particularly in cancer, neurodevelopmental disorders, and metabolic diseases. Epigenetic dysregulation is now recognized as a hallmark of cancer, with global hypomethylation and gene-specific hypermethylation common across tumor types. Emerging epigenetic therapeutics include DNMT inhibitors, HDAC inhibitors, and approaches targeting reader proteins of epigenetic marks. The field's evolution has benefited from technological advances including bisulfite sequencing, ChIP-seq, and ATAC-seq, enabling genome-wide epigenetic profiling at unprecedented resolution.\n",
    "\n",
    "Flashcards:\n",
    "[\n",
    "  {{\n",
    "    \"front\": \"Epigenetics\",\n",
    "    \"back\": \"The study of heritable changes in gene expression that don't involve alterations to the underlying DNA sequence.\",\n",
    "    \"category\": \"Molecular Biology\"\n",
    "  }},\n",
    "  {{\n",
    "    \"front\": \"DNA methylation\",\n",
    "    \"back\": \"An epigenetic mechanism involving the addition of a methyl group to the 5' position of cytosine in CpG dinucleotides, often resulting in gene silencing.\",\n",
    "    \"category\": \"Epigenetic Mechanisms\"\n",
    "  }},\n",
    "  {{\n",
    "    \"front\": \"Histone code\",\n",
    "    \"back\": \"The combination of various histone modifications (including acetylation, methylation, phosphorylation, and ubiquitination) that influences chromatin structure and gene accessibility.\",\n",
    "    \"category\": \"Chromatin Biology\"\n",
    "  }},\n",
    "  {{\n",
    "    \"front\": \"Transgenerational epigenetic inheritance\",\n",
    "    \"back\": \"The persistence of environmentally-induced epigenetic changes across generations through mechanisms like incomplete erasure during gametogenesis.\",\n",
    "    \"category\": \"Inheritance Patterns\"\n",
    "  }},\n",
    "  {{\n",
    "    \"front\": \"Epigenetic dysregulation in cancer\",\n",
    "    \"back\": \"A hallmark of cancer characterized by global hypomethylation and gene-specific hypermethylation across tumor types.\",\n",
    "    \"category\": \"Cancer Biology\"\n",
    "  }},\n",
    "  {{\n",
    "    \"front\": \"Bisulfite sequencing\",\n",
    "    \"back\": \"A technology used for genome-wide epigenetic profiling that enables detection of DNA methylation patterns at single-nucleotide resolution.\",\n",
    "    \"category\": \"Epigenomic Technologies\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "Now, based on the following summary, create up to {max_cards} flashcards:\n",
    "\n",
    "HERE IS THE SUMMARY:\n",
    "{summary_text}\n",
    "\n",
    "Respond ONLY with the properly formatted JSON array of flashcards. Do not include any introductory or explanatory text.\n",
    "\"\"\"\n",
    "        \n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        try:\n",
    "            json_text = response.text\n",
    "            if \"```json\" in json_text:\n",
    "                json_text = json_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "            elif \"```\" in json_text:\n",
    "                json_text = json_text.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "                \n",
    "            flashcards_data = json.loads(json_text)\n",
    "            \n",
    "            if not flashcards_data:\n",
    "                print(\"No definitions found in the summary text.\")\n",
    "                \n",
    "            return flashcards_data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from flashcard generation: {e}\")\n",
    "            print(\"Response received:\", response.text[:100] + \"...\")\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating flashcards: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befbae5f",
   "metadata": {
    "papermill": {
     "duration": 0.006951,
     "end_time": "2025-04-22T07:06:09.084776",
     "exception": false,
     "start_time": "2025-04-22T07:06:09.077825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Function Display Flashcards\n",
    "- Display flashcards in an **interactive command-line interface.**\n",
    "- **Takes flashcards_data as input**, checking if it's empty before proceeding\n",
    "- **Displays a header** showing the total number of flashcards available for review\n",
    "- **Shuffles the flashcards randomly** to provide varied learning experiences\n",
    "- For each flashcard, shows the term first, waits for user input, then **reveals the definition**\n",
    "- **Tracks progress** by displaying the current flashcard number and its category, ending with a completion message when finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd758354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:06:09.100592Z",
     "iopub.status.busy": "2025-04-22T07:06:09.099434Z",
     "iopub.status.idle": "2025-04-22T07:06:09.106274Z",
     "shell.execute_reply": "2025-04-22T07:06:09.105262Z"
    },
    "papermill": {
     "duration": 0.016388,
     "end_time": "2025-04-22T07:06:09.107852",
     "exception": false,
     "start_time": "2025-04-22T07:06:09.091464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_flashcards(flashcards_data):\n",
    "    if not flashcards_data:\n",
    "        print(\"No definitions found for flashcard creation.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n===== DEFINITION FLASHCARDS ({len(flashcards_data)}) =====\")\n",
    "    print(\"Review the following term definitions to reinforce your learning.\\n\")\n",
    "    \n",
    "    random.shuffle(flashcards_data)\n",
    "    \n",
    "    for i, card in enumerate(flashcards_data, 1):\n",
    "        print(f\"\\nFlashcard {i}/{len(flashcards_data)} - Category: {card.get('category', 'General')}\")\n",
    "        print(f\"Term: {card['front']}\")\n",
    "        input(\"Press click 'Enter' to reveal definition...\")\n",
    "        print(f\"Definition: {card['back']}\")\n",
    "        \n",
    "        if i < len(flashcards_data):\n",
    "            input(\"\\nPress click 'Enter' for next flashcard...\")\n",
    "    \n",
    "    print(\"\\n===== Flashcards Complete =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c23ed",
   "metadata": {
    "papermill": {
     "duration": 0.006484,
     "end_time": "2025-04-22T07:06:09.121157",
     "exception": false,
     "start_time": "2025-04-22T07:06:09.114673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Function to summarize the youtube video\n",
    "- Specialized function for YouTube videos that extracts video ID and calls process_content.\n",
    "- Takes video_link as primary input along with optional parameters including **language_code (defaults to 'en')**, **save_to_file (boolean)**, **generate_quiz_questions (boolean)**, and **generate_flashcards_bool (boolean)**\n",
    "- Extracts the YouTube video ID from the provided link using an **extract_video_id** function\n",
    "- Delegates processing to a **process_content** function, specifically identifying the content type as \"youtube\"\n",
    "- Implements exception handling to catch and return any errors that occur during processing\n",
    "- Returns the processing result or an error message with markdown formatting if the process fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73c16635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:06:09.135636Z",
     "iopub.status.busy": "2025-04-22T07:06:09.135237Z",
     "iopub.status.idle": "2025-04-22T07:06:09.141560Z",
     "shell.execute_reply": "2025-04-22T07:06:09.140336Z"
    },
    "papermill": {
     "duration": 0.015691,
     "end_time": "2025-04-22T07:06:09.143381",
     "exception": false,
     "start_time": "2025-04-22T07:06:09.127690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize_youtube_video(video_link, language_code='en', save_to_file=True, \n",
    "                           generate_quiz_questions=True, generate_flashcards_bool=True):\n",
    "    try:\n",
    "        video_id = extract_video_id(video_link)\n",
    "\n",
    "        return process_content(\n",
    "            video_link, \n",
    "            video_id,\n",
    "            content_type=\"youtube\",\n",
    "            language_code=language_code,\n",
    "            save_to_file=save_to_file,\n",
    "            generate_quiz_questions=generate_quiz_questions,\n",
    "            generate_flashcards_bool=generate_flashcards_bool\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_message = f\"# Error Processing Video\\n\\n{str(e)}\"\n",
    "        return error_message, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2733657",
   "metadata": {
    "papermill": {
     "duration": 0.006377,
     "end_time": "2025-04-22T07:06:09.156606",
     "exception": false,
     "start_time": "2025-04-22T07:06:09.150229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Function to save the markdown summary to a file\n",
    "- Three functions **(save_markdown_summary, save_quiz, save_flashcards)** all follow the same pattern of accepting content data and a **video_id parameter** to create uniquely named files\n",
    "- Each function has a default output_dir parameter that specifies the target directory **(\"summaries\", \"quizzes\", or \"flashcards\")**\n",
    "- The functions implement directory creation logic with **os.path.exists()** and **os.makedirs()** for their respective content types\n",
    "- File handling utilizes **open()** with **\"w\" mode** and **UTF-8 encoding**, writing either text directly or **JSON** data serialized with **json.dump()** and an **indent of 2**\n",
    "- All functions include exception handling with try/except blocks that log errors and return either the created filename or None on failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c6fede7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:06:09.172116Z",
     "iopub.status.busy": "2025-04-22T07:06:09.171814Z",
     "iopub.status.idle": "2025-04-22T07:06:09.180852Z",
     "shell.execute_reply": "2025-04-22T07:06:09.179798Z"
    },
    "papermill": {
     "duration": 0.018836,
     "end_time": "2025-04-22T07:06:09.182491",
     "exception": false,
     "start_time": "2025-04-22T07:06:09.163655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_markdown_summary(summary, video_id, output_dir=\"summaries\"):\n",
    "    try:\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            \n",
    "        filename = f\"{output_dir}/summary_{video_id}.md\"\n",
    "        \n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(summary)\n",
    "            \n",
    "        return filename\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving summary: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_quiz(quiz_data, video_id, output_dir=\"quizzes\"):\n",
    "    try:\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            \n",
    "        filename = f\"{output_dir}/quiz_{video_id}.json\"\n",
    "        \n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(quiz_data, f, indent=2)\n",
    "            \n",
    "        return filename\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving quiz: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_flashcards(flashcards_data, video_id, output_dir=\"flashcards\"):\n",
    "    try:\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            \n",
    "        filename = f\"{output_dir}/flashcards_{video_id}.json\"\n",
    "        \n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(flashcards_data, f, indent=2)\n",
    "            \n",
    "        return filename\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving flashcards: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e496c3",
   "metadata": {
    "papermill": {
     "duration": 0.006784,
     "end_time": "2025-04-22T07:06:09.196012",
     "exception": false,
     "start_time": "2025-04-22T07:06:09.189228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Function to process content\n",
    "Main function to process content (YouTube video or document) and generate study materials.\n",
    "Returns the generated content and study materials.\n",
    "    \n",
    "**Parameters**:\n",
    "- content: URL for YouTube video or text content for document\n",
    "- content_id: Video ID or document name\n",
    "- content_type: \"youtube\" or \"document\"\n",
    "- language_code: Language code for transcripts (YouTube only)\n",
    "- save_to_file: Whether to save outputs to files\n",
    "- generate_quiz_questions: Whether to generate quiz\n",
    "- generate_flashcards_bool: Whether to generate flashcards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a02b828d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:06:09.211248Z",
     "iopub.status.busy": "2025-04-22T07:06:09.210829Z",
     "iopub.status.idle": "2025-04-22T07:06:09.219456Z",
     "shell.execute_reply": "2025-04-22T07:06:09.218437Z"
    },
    "papermill": {
     "duration": 0.018369,
     "end_time": "2025-04-22T07:06:09.221195",
     "exception": false,
     "start_time": "2025-04-22T07:06:09.202826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_content(content, content_id, content_type=\"youtube\", language_code='en', save_to_file=True, \n",
    "                    generate_quiz_questions=True, generate_flashcards_bool=True):\n",
    "    try:\n",
    "        filterwarnings(action='ignore')\n",
    "        \n",
    "        load_dotenv()\n",
    "        \n",
    "        if content_type == \"youtube\":\n",
    "            print(\"Extracting transcript...\")\n",
    "            content_text = extract_transcript(content_id, language_code)\n",
    "            \n",
    "            if not content_text:\n",
    "                return \"# Transcript Extraction Failed\\n\\nThe video might not have subtitles.\", None, None\n",
    "        else:\n",
    "            content_text = content\n",
    "        \n",
    "        print(\"Generating markdown summary...\")\n",
    "        markdown_summary = generate_markdown_summary(content_text, content_id if content_type == \"youtube\" else None)\n",
    "        \n",
    "        if not markdown_summary:\n",
    "            return \"# Summary Generation Failed\\n\\nUnable to generate a summary from the content.\", None, None\n",
    "        \n",
    "        if save_to_file:\n",
    "            output_dir = \"summaries\"\n",
    "            saved_path = save_markdown_summary(markdown_summary, content_id)\n",
    "            if saved_path:\n",
    "                print(f\"Summary saved to: {saved_path}\")\n",
    "    \n",
    "        quiz_data = None\n",
    "        flashcards_data = None\n",
    "        \n",
    "        if generate_quiz_questions:\n",
    "            print(\"Generating quiz questions...\")\n",
    "            quiz_data = generate_quiz(markdown_summary)\n",
    "            \n",
    "            if save_to_file and quiz_data:\n",
    "                saved_quiz_path = save_quiz(quiz_data, content_id)\n",
    "                if saved_quiz_path:\n",
    "                    print(f\"Quiz saved to: {saved_quiz_path}\")\n",
    "        \n",
    "        if generate_flashcards_bool:\n",
    "            print(\"Generating flashcards...\")\n",
    "            flashcards_data = generate_flashcards(markdown_summary)\n",
    "            \n",
    "            if save_to_file and flashcards_data:\n",
    "                saved_flashcards_path = save_flashcards(flashcards_data, content_id)\n",
    "                if saved_flashcards_path:\n",
    "                    print(f\"Flashcards saved to: {saved_flashcards_path}\")\n",
    "        \n",
    "        return markdown_summary, quiz_data, flashcards_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_message = f\"# Error Processing Content\\n\\n{str(e)}\"\n",
    "        return error_message, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d7fdba",
   "metadata": {
    "papermill": {
     "duration": 0.00658,
     "end_time": "2025-04-22T07:06:09.235357",
     "exception": false,
     "start_time": "2025-04-22T07:06:09.228777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main Function\n",
    "- Main entry point (`if __name__ == '__main__'`) establishes a command-line interface for the Learning Content Processor\n",
    "- Calls **configure_genai()** to set up the **Google Generative AI API**, exiting with **sys.exit(1) if configuration fails**\n",
    "- Collects user input for **video_url** and boolean preferences for quiz and flashcard generation\n",
    "- Invokes **summarize_youtube_video()** with **parameters: video_url, language_code='en', save_to_file=True, and user-defined boolean flags** for content generation\n",
    "- Unpacks the returned tuple into three variables: **markdown_summary, quiz_data, and flashcards_data**\n",
    "- Uses Jupyter's **display()** function with a Markdown renderer to present the formatted summary\n",
    "- **Conditionally calls run_quiz()** with quiz_data if data exists and user confirms they want to take the quiz\n",
    "- Similarly **calls display_flashcards()** with flashcards_data if available and user wishes to review them\n",
    "- Implements exception handling for KeyboardInterrupt to manage user-initiated cancellations\n",
    "- Includes a general Exception handler to catch and display any unexpected errors during execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8bbb458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:06:09.250161Z",
     "iopub.status.busy": "2025-04-22T07:06:09.249811Z",
     "iopub.status.idle": "2025-04-22T07:06:09.451442Z",
     "shell.execute_reply": "2025-04-22T07:06:09.450315Z"
    },
    "papermill": {
     "duration": 0.21136,
     "end_time": "2025-04-22T07:06:09.453265",
     "exception": false,
     "start_time": "2025-04-22T07:06:09.241905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Content Processor\n",
      "======================================\n",
      "An unexpected error occurred: raw_input was called, but this frontend does not support input requests.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"Learning Content Processor\")\n",
    "    print(\"======================================\")\n",
    "    \n",
    "    if not configure_genai():\n",
    "        print(\"ERROR: Failed to configure Google Generative AI API.\")\n",
    "        print(\"Please ensure you've added the GENAI_API_KEY to your Kaggle secrets.\")\n",
    "        import sys\n",
    "        sys.exit(1)\n",
    "    \n",
    "    try:\n",
    "        video_url = input(\"Enter YouTube Video URL: \")\n",
    "            \n",
    "        generate_quiz_option = input(\"Generate quiz? (y/n): \").lower() == 'y'\n",
    "        generate_flashcards_option = input(\"Generate flashcards? (y/n): \").lower() == 'y'\n",
    "            \n",
    "        markdown_summary, quiz_data, flashcards_data = summarize_youtube_video(\n",
    "            video_url, \n",
    "            language_code='en', \n",
    "            save_to_file=True, \n",
    "            generate_quiz_questions=generate_quiz_option,\n",
    "            generate_flashcards_bool=generate_flashcards_option\n",
    "        )\n",
    "            \n",
    "        \n",
    "        print(\"\\n--- MARKDOWN SUMMARY ---\\n\")\n",
    "        display(Markdown(markdown_summary))\n",
    "        \n",
    "        if quiz_data and input(\"\\nTake the quiz now? (y/n): \").lower() == 'y':\n",
    "            quiz_results = run_quiz(quiz_data)\n",
    "        \n",
    "        if flashcards_data and input(\"\\nReview flashcards now? (y/n): \").lower() == 'y':\n",
    "            display_flashcards(flashcards_data)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nOperation cancelled by user.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.758457,
   "end_time": "2025-04-22T07:06:10.282701",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-22T07:05:49.524244",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
